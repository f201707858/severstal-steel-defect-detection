# -*- coding: utf-8 -*-
"""SteelDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/178FO_XwXl6dV3lKjvl2vTxRQG-iQZ0c1
"""

import warnings
warnings.filterwarnings('ignore', category=UserWarning, module='skimage')
from keras.models import *
from keras.layers import *
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Conv2D ,Flatten ,Conv2DTranspose
import cv2
import os
from keras.preprocessing.image import ImageDataGenerator
from tqdm import tqdm
import glob
import shutil
import os
from shutil import copyfile

from google.colab import drive
drive.mount('/content/drive')

# from google.colab import files
# uploaded = files.upload()

#!unzip 'train_images'
from google.colab import drive
!jar xvf "/content/drive/My Drive/train_images.zip"

def rle_decode(mask_rle,category = None , shape=(1600, 256)):
    encodedString = str(mask_rle).split(" ")
    flatmask = np.zeros(1600*256, dtype=np.int16)
    for i in range(0,len(encodedString)//2):
        start = int(encodedString[2*i])
        end = int(encodedString[2*i]) + int(encodedString[2*i+1])
        if(category == None):
            flatmask[start:end-1] = 255
        else:    
            flatmask[start:end-1] =  category * 50
    return np.transpose(flatmask.reshape(shape))

file = open('train.csv').read().split("\n")
masks = []
images = []
img_p = "train_images/"
# label_img_p = "/home/yamini/Desktop/shit/severstal-steel-defect-detection/label_img_p"
# mask4_p = "/home/yamini/Desktop/shit/severstal-steel-defect-detection/masks4"


#shutil.rmtree(mask4_p,ignore_errors=True)
os.makedirs("mask4_p",exist_ok=True)
c_img_n  = " "
c_m = None

for i in tqdm(range(1,len(file))):
    line = file[i]
    if("," in line):
        img_n,lab = line.split(",")
        img_n,img_c = img_n.split("_")
        if not lab == 'NaN':
            img = cv2.imread(os.path.join(img_p,img_n),0)
            if(c_img_n != img_n):
                if(not(c_m is None)):
                   # if(len(np.argwhere(0<c_m.any()< 255))>0):
                    cv2.imwrite(os.path.join("mask4_p" + '/' ,c_img_n),c_m)
                c_img_n = img_n
                c_m = rle_decode(lab ,int(img_c))
            else:
                c_m = np.maximum(rle_decode(lab,int(img_c)),c_m)

import warnings
import keras
warnings.filterwarnings('ignore', category=UserWarning, module='skimage')
from keras.models import *
from keras.layers import *
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Conv2D ,Flatten ,Conv2DTranspose
import cv2
import os
from keras.preprocessing.image import ImageDataGenerator
from tqdm import tqdm
import glob
import shutil
import os
from shutil import copyfile

"""# New Section"""

class Unet():
    def __init__(self):
        self.modelx = keras.layers.Input((256,1600,1))
    def contract_block(self,model,filters,kernel = 3 ,activation = "relu"):
        model1 = Conv2D(filters,(kernel,kernel), activation= activation, kernel_initializer='he_normal',padding='same')(model) 
        model2 = BatchNormalization(axis = -1)(model1)
        model3 = Conv2D(filters, (kernel, kernel), activation= activation, kernel_initializer='he_normal',padding='same')(model1)
        model4 = BatchNormalization(axis = -1)(model1)
        return model4
    def expansive_block(self,model,filters,output_filters,kernel = 3 ,activation = "relu"):
        model1= Conv2D(filters, (kernel, kernel), activation= activation, kernel_initializer='he_normal',padding='same')(model)
        model2 =BatchNormalization(axis =  -1)(model1)
        model3 = Conv2D(filters, (kernel, kernel), activation= activation, kernel_initializer='he_normal',padding='same')(model2)
        model4 = BatchNormalization(axis =  -1)(model3)
        model6 =  Conv2DTranspose(output_filters , (5,5) , strides=2,padding='same')(model4)
        return model6
    def final_block(self,model,filters,output_filters ,kernel = 3 ,activation = "relu"):
        model1 = Conv2D(filters, (kernel, kernel), activation= activation, kernel_initializer='he_normal',padding='same')(model)
        model2 = BatchNormalization(axis = -1)(model1)
        model3 = Conv2D(filters, (kernel, kernel), activation= activation, kernel_initializer='he_normal',padding='same')(model2)
        model4 = BatchNormalization(axis = -1)(model3)
        model6 = Conv2DTranspose(output_filters,(kernel,kernel), activation= activation, 
                                 kernel_initializer='he_normal',padding='same',strides=2)(model4)
        model7 = BatchNormalization(axis = -1)(model6)    
        model8 = Conv2D(output_filters, (1,1), activation= activation, kernel_initializer='he_normal',
                        padding='same')(model7)
        model8 = BatchNormalization(axis = -1)(model8)
        return model8 
    def forward(self):
        conv_encode1 = self.contract_block( self.modelx, 64)
        conv_maxpool1 = MaxPooling2D(pool_size=(2, 2),strides = 2)(conv_encode1)
        conv_encode2 = self.contract_block(conv_maxpool1,128)
        conv_maxpool2 = MaxPooling2D(pool_size=(2, 2),strides = 2)(conv_encode2)
        conv_encode3 = self.contract_block(conv_maxpool2 , 160)
        conv_maxpool3 = MaxPooling2D(pool_size=(2, 2),strides = 2)(conv_encode3)
        conv_encode4 = self.contract_block(conv_maxpool3 , 192)
        conv_maxpool4= MaxPooling2D(pool_size=(2, 2),strides = 2)(conv_encode4)
        # Bottleneck
        bottleneck = Conv2D(256,kernel_size=3,activation = "relu",padding='same')(conv_maxpool4)
        bottleneck1 = BatchNormalization(axis=-1)(bottleneck)
        bottleneck2 = Conv2D(256,kernel_size=3,activation = "relu",padding='same')(bottleneck1)
        bottleneck3 = BatchNormalization(axis = -1)(bottleneck2)
        bottleneck4 = Conv2DTranspose(256, kernel_size=4, strides=2,padding='same')(bottleneck3)
        # Decode
    
        decode_block3 = Concatenate(axis=-1)([conv_encode4 ,bottleneck4])
        cat_layer2 = self.expansive_block(decode_block3,filters =  192, output_filters = 192)#512
        decode_block2 = Concatenate(axis=-1)([conv_encode3 ,cat_layer2])
        cat_layer3 = self.expansive_block(decode_block2 , filters=  160, output_filters = 160) #256
        decode_block3 = Concatenate(axis=-1)([conv_encode2 ,cat_layer3])
        end = self.final_block(decode_block3 , filters=  64, output_filters= 1) #128
        model = keras.models.Model(self.modelx,end)
        model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])
        return model

import keras
seed  = 5
data_gen_args = dict(
                     rotation_range=90,
                     width_shift_range=0.1,
                     height_shift_range=0.1,
                     zoom_range=0.2)
image_datagen = ImageDataGenerator(**data_gen_args)
mask_datagen = ImageDataGenerator(**data_gen_args)


image_generator = image_datagen.flow_from_directory(
     "/content/drive/My Drive/label_img_p",
    class_mode=None,target_size=(256,1600),
    color_mode='grayscale',batch_size = 3,
    seed=seed)

mask_generator = mask_datagen.flow_from_directory(
    "/content/drive/My Drive/masks4",color_mode='grayscale',
    class_mode=None,target_size=(256,1600),batch_size = 3,
    seed=seed)

# combine generators into one which yields image and masks
train_generator = zip(image_generator, mask_generator)
model  = Unet()
model = model.forward()
model.fit_generator(train_generator,100,verbose=1,epochs=12)

size =0
for root ,sub,files in os.walk("/content/drive/My Drive/masks4/0"):
  size = files.length()

#Implementation of X-net and then model formation with dice coefficient and test set accuracy and then preprocessing image(Hardik)
from keras.models import Model
from keras.layers import Input, Concatenate, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D
from keras.layers import BatchNormalization, Reshape, Layer
from keras.layers import Activation, Flatten, Dense
from keras.optimizers import *
from keras.callbacks import ModelCheckpoint, LearningRateScheduler
from keras.metrics import categorical_accuracy
from keras import backend as K
from keras import losses


def model(input_shape=(256, 1600, 3), classes=3, kernel_size = 3, filter_depth = (64,128,256,512,0)):
  img_input = Input(shape=input_shape)
  # Encoder
  conv1 = Conv2D(filter_depth[0], (kernel_size, kernel_size), padding="same")(img_input)
  batch1 = BatchNormalization()(conv1)
  act1 = Activation("relu")(batch1)
  pool1 = MaxPooling2D(pool_size=(2, 2))(act1)
  #100*100
  
  conv2 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding="same")(pool1)
  batch2 = BatchNormalization()(conv2)
  act2 = Activation("relu")(batch2)
  pool2 = MaxPooling2D(pool_size=(2, 2))(act2)
  #50x50

  conv3 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding="same")(pool2)
  batch3 = BatchNormalization()(conv3)
  act3 = Activation("relu")(batch3)
  pool3 = MaxPooling2D(pool_size=(2, 2))(act3)
  #25x25


  #Flat
  conv4 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding="same")(pool3)
  batch4 = BatchNormalization()(conv4)
  act4 = Activation("relu")(batch4)
  #25x25

  conv5 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding="same")(act4)
  batch5 = BatchNormalization()(conv5)
  act5 = Activation("relu")(batch5)
  #25x25

  #Up
  up6 = UpSampling2D(size=(2, 2))(act5)
  conv6 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding="same")(up6)
  batch6 = BatchNormalization()(conv6)
  act6 = Activation("relu")(batch6)
  concat6 = Concatenate()([act3,act6])
  #50x50

  up7 = UpSampling2D(size=(2, 2))(concat6)
  conv7 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding="same")(up7)
  batch7 = BatchNormalization()(conv7)
  act7 = Activation("relu")(batch7)
  concat7 = Concatenate()([act2,act7])
  #100x100


  #Down
  conv8 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding="same")(concat7)
  batch8 = BatchNormalization()(conv8)
  act8 = Activation("relu")(batch8)
  pool8 = MaxPooling2D(pool_size=(2, 2))(act8)
  #50x50
    
  conv9 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding="same")(pool8)
  batch9 = BatchNormalization()(conv9)
  act9 = Activation("relu")(batch9)
  pool9 = MaxPooling2D(pool_size=(2, 2))(act9)
  #25x25
    
  #Flat
  conv10 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding="same")(pool9)
  batch10 = BatchNormalization()(conv10)
  act10 = Activation("relu")(batch10)
  #25x25
  
  conv11 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding="same")(act10)
  batch11 = BatchNormalization()(conv11)
  act11 = Activation("relu")(batch11)
  #25x25

  #Encoder
  up12 = UpSampling2D(size=(2, 2))(act11)
  conv12 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding="same")(up12)
  batch12 = BatchNormalization()(conv12)
  act12 = Activation("relu")(batch12)
  concat12 = Concatenate()([act9,act12])
  #50x50


  up13 = UpSampling2D(size=(2, 2))(concat12)
  conv13 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding="same")(up13)
  batch13 = BatchNormalization()(conv13)
  act13 =  Activation("relu")(batch13)
  concat13 = Concatenate()([act8,act13])
  #100x100
    
  up14 = UpSampling2D(size=(2, 2))(concat13)
  conv14 = Conv2D(filter_depth[0], (kernel_size, kernel_size), padding="same")(up14)
  batch14 = BatchNormalization()(conv14)
  act14 = Activation("relu")(batch14)
  concat14 = Concatenate()([act1,act14])
  #200x200

 
  # conv15 = Conv2D(classes, (1,1), padding="valid")(concat14)
  # reshape15 = Reshape((input_shape[0]*input_shape[1],classes))(conv15)
  # act15 = Activation("softmax")(reshape15)

  conv15 = Conv2D(1,(kernel_size,kernel_size),padding = "same")(concat14) 
  act15 = Reshape(((input_shape[0],input_shape[1]),))(conv15)

  model = Model(img_input, act15)

  return model

from keras import backend as K
def dice_coef(y_true, y_pred, smooth=1):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)

def dice_loss(y_true, y_pred):
    smooth = 1.
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = y_true_f * y_pred_f
    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)
    return 1. - score

def bce_dice_loss(y_true, y_pred):
    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)

import keras
seed  = 5
data_gen_args = dict(rotation_range=90,
                     width_shift_range=0.1,
                     height_shift_range=0.1,
                     zoom_range=0.2)
image_datagen = ImageDataGenerator(**data_gen_args)
mask_datagen = ImageDataGenerator(**data_gen_args)


image_generator = image_datagen.flow_from_directory(
     "/content/drive/My Drive/label_img_p",
    class_mode=None,target_size=(256,1600),
    color_mode='grayscale',batch_size = 3,
    seed=seed)

mask_generator = mask_datagen.flow_from_directory(
    "/content/drive/My Drive/masks4",color_mode='grayscale',
    class_mode=None,target_size=(256,1600),batch_size = 3,
    seed=seed)

# combine generators into one which yields image and masks
train_generator = zip(image_generator, mask_generator)

model.compile(optimizer=AccumOptimizer(Adam(2e-3), 4), loss=bce_dice_loss, metrics=[dice_coef])

#model.fit_generator(train_generator,100,verbose=1,epochs=12)
history = model.fit_generator(
    train_generator,
    validation_data=100,
 #   callbacks=[checkpoint],
    verbose=1,
    epochs=30
)